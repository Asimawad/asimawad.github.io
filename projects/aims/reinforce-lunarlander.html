<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>REINFORCE - LunarLander | Asim Osman</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .gradient-text {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        code, .mono { font-family: 'Fira Code', monospace; }
        .result-img {
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-900">
    <nav class="fixed top-0 w-full bg-white/80 backdrop-blur-md z-50 border-b border-gray-100">
        <div class="max-w-4xl mx-auto px-6 py-4 flex justify-between items-center">
            <a href="/" class="text-xl font-bold gradient-text">AO</a>
            <a href="/journey.html#chapter-2" class="text-gray-600 hover:text-gray-900">‚Üê Back to Journey</a>
        </div>
    </nav>

    <main class="pt-24 pb-16">
        <div class="max-w-4xl mx-auto px-6">
            <!-- Header -->
            <div class="mb-8">
                <div class="flex items-center gap-3 mb-4">
                    <span class="text-4xl">üåô</span>
                    <span class="text-xs bg-green-100 text-green-700 px-3 py-1 rounded-full font-medium">AIMS Coursework</span>
                </div>
                <h1 class="text-4xl font-bold">REINFORCE ‚Äî LunarLander</h1>
                <p class="text-gray-500 mt-2 text-lg">Late 2024 ‚Äî Policy Gradient for Complex Control</p>
                <div class="flex flex-wrap gap-3 mt-4">
                    <span class="text-xs bg-indigo-100 text-indigo-700 px-2 py-1 rounded">Policy Gradient</span>
                    <span class="text-xs bg-indigo-100 text-indigo-700 px-2 py-1 rounded">REINFORCE</span>
                    <span class="text-xs bg-indigo-100 text-indigo-700 px-2 py-1 rounded">LunarLander-v2</span>
                    <span class="text-xs bg-indigo-100 text-indigo-700 px-2 py-1 rounded">5000+ episodes</span>
                </div>
            </div>

            <!-- About -->
            <section class="mb-10">
                <h2 class="text-xl font-semibold mb-4">About</h2>
                <p class="text-gray-600 text-lg leading-relaxed">
                    Applying the REINFORCE policy gradient algorithm to the challenging LunarLander-v2 environment. 
                    The agent must learn to control thrust in multiple directions to safely land on the target pad 
                    using only episodic returns for learning.
                </p>
                <a href="https://github.com/Asimawad/Reinforcement-Learning-LunarLander-REINFORCE" target="_blank" 
                   class="inline-flex items-center gap-2 mt-4 text-indigo-600 hover:text-indigo-700 font-medium">
                    View on GitHub ‚Üí
                </a>
            </section>

            <!-- Environment -->
            <section class="mb-10">
                <h2 class="text-xl font-semibold mb-4">Environment: LunarLander-v2</h2>
                <div class="grid grid-cols-2 md:grid-cols-4 gap-4">
                    <div class="bg-white p-3 rounded-lg border text-center">
                        <p class="text-2xl font-bold text-indigo-600">8</p>
                        <p class="text-xs text-gray-500">State dims</p>
                    </div>
                    <div class="bg-white p-3 rounded-lg border text-center">
                        <p class="text-2xl font-bold text-green-600">4</p>
                        <p class="text-xs text-gray-500">Actions</p>
                    </div>
                    <div class="bg-white p-3 rounded-lg border text-center">
                        <p class="text-2xl font-bold text-amber-600">5000+</p>
                        <p class="text-xs text-gray-500">Episodes</p>
                    </div>
                    <div class="bg-white p-3 rounded-lg border text-center">
                        <p class="text-2xl font-bold text-gray-600">128</p>
                        <p class="text-xs text-gray-500">Batch size</p>
                    </div>
                </div>
            </section>

            <!-- Implementation -->
            <section class="mb-12">
                <h2 class="text-2xl font-bold mb-6 pb-2 border-b">Implementation Details</h2>
                
                <div class="bg-white p-4 rounded-lg border mb-4">
                    <h3 class="font-semibold text-indigo-600 mb-2">Key Components</h3>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li>‚Ä¢ <strong>Policy Network:</strong> FC network outputting action logits</li>
                        <li>‚Ä¢ <strong>Returns Calculation:</strong> Discounted Monte Carlo returns</li>
                        <li>‚Ä¢ <strong>Loss:</strong> Log-probability weighted by returns</li>
                        <li>‚Ä¢ <strong>Optimizer:</strong> Adam with learning rate adjustments</li>
                    </ul>
                </div>

                <div class="bg-amber-50 border border-amber-200 p-4 rounded-lg">
                    <p class="text-amber-800"><strong>Challenge:</strong> LunarLander is harder than CartPole for REINFORCE due to sparse rewards and longer episodes. Required 5000+ episodes vs ~2500 for CartPole.</p>
                </div>
            </section>

            <!-- Results -->
            <section class="mb-12">
                <h2 class="text-2xl font-bold mb-6 pb-2 border-b">Results</h2>

                <img src="https://raw.githubusercontent.com/Asimawad/Reinforcement-Learning-LunarLander-REINFORCE/main/visuals/policy.png" 
                     alt="REINFORCE LunarLander Training" class="result-img w-full mb-4">
                <p class="text-sm text-gray-500 mb-6">Training curve showing gradual improvement as agent learns landing behavior</p>

                <div class="bg-white p-4 rounded-lg border">
                    <h4 class="font-medium mb-2">Training Progress:</h4>
                    <ul class="space-y-1 text-gray-600 text-sm">
                        <li>‚Ä¢ <strong>Initial:</strong> Highly negative rewards (crashes)</li>
                        <li>‚Ä¢ <strong>Mid-training:</strong> Gradual improvement as agent explores</li>
                        <li>‚Ä¢ <strong>Final:</strong> Moderate stability with successful landings</li>
                    </ul>
                </div>
            </section>

            <!-- Comparison -->
            <section class="mb-10">
                <h2 class="text-xl font-semibold mb-4">REINFORCE vs DQN on LunarLander</h2>
                <div class="bg-white p-4 rounded-lg border">
                    <ul class="space-y-2 text-gray-600">
                        <li>‚Ä¢ <strong>DQN:</strong> Faster convergence (~700 episodes), higher final performance (250+)</li>
                        <li>‚Ä¢ <strong>REINFORCE:</strong> Slower (5000+ episodes), more variance, but simpler implementation</li>
                        <li>‚Ä¢ <strong>Why:</strong> REINFORCE uses full episode returns (high variance) while DQN uses TD learning with replay buffer (lower variance)</li>
                    </ul>
                </div>
            </section>

            <!-- Key Takeaways -->
            <section class="mb-10">
                <h2 class="text-xl font-semibold mb-4">Key Takeaways</h2>
                <div class="bg-gradient-to-r from-green-50 to-emerald-50 p-6 rounded-xl">
                    <ul class="space-y-3 text-gray-700">
                        <li>‚úÖ <strong>REINFORCE works</strong> but requires many more episodes than DQN</li>
                        <li>‚úÖ <strong>High variance</strong> from Monte Carlo returns slows learning</li>
                        <li>‚úÖ <strong>On-policy nature</strong> means no experience replay benefit</li>
                        <li>‚úÖ <strong>Future improvement:</strong> Add baseline (A2C) to reduce variance</li>
                    </ul>
                </div>
            </section>

            <!-- Footer Links -->
            <div class="flex justify-between items-center pt-6 border-t">
                <a href="/journey.html#chapter-2" class="text-gray-600 hover:text-gray-900">‚Üê Back to Journey</a>
                <a href="https://github.com/Asimawad/Reinforcement-Learning-LunarLander-REINFORCE" target="_blank" 
                   class="bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-800 transition">
                    View on GitHub
                </a>
            </div>
        </div>
    </main>

    <footer class="py-8 bg-gray-900">
        <div class="max-w-4xl mx-auto px-6 text-center text-gray-500 text-sm">
            ¬© 2025 Asim Osman
        </div>
    </footer>
</body>
</html>
