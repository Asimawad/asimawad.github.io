<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Denoising Autoencoder | Asim Osman</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .gradient-text {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        code, .mono { font-family: 'Fira Code', monospace; }
        .result-img {
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-900">
    <nav class="fixed top-0 w-full bg-white/80 backdrop-blur-md z-50 border-b border-gray-100">
        <div class="max-w-4xl mx-auto px-6 py-4 flex justify-between items-center">
            <a href="/" class="text-xl font-bold gradient-text">AO</a>
            <a href="/journey.html#chapter-2" class="text-gray-600 hover:text-gray-900">‚Üê Back to Journey</a>
        </div>
    </nav>

    <main class="pt-24 pb-16">
        <div class="max-w-4xl mx-auto px-6">
            <!-- Header -->
            <div class="mb-8">
                <div class="flex items-center gap-3 mb-4">
                    <span class="text-4xl">üñºÔ∏è</span>
                    <span class="text-xs bg-blue-100 text-blue-700 px-3 py-1 rounded-full font-medium">AIMS Coursework</span>
                </div>
                <h1 class="text-4xl font-bold">Image Denoising Autoencoder</h1>
                <p class="text-gray-500 mt-2 text-lg">Late 2024 ‚Äî Fully Convolutional Network for Noise Removal</p>
                <div class="flex flex-wrap gap-3 mt-4">
                    <span class="text-xs bg-indigo-100 text-indigo-700 px-2 py-1 rounded">Autoencoder</span>
                    <span class="text-xs bg-indigo-100 text-indigo-700 px-2 py-1 rounded">Denoising</span>
                    <span class="text-xs bg-indigo-100 text-indigo-700 px-2 py-1 rounded">FCN</span>
                    <span class="text-xs bg-indigo-100 text-indigo-700 px-2 py-1 rounded">LFWcrop</span>
                </div>
            </div>

            <!-- About -->
            <section class="mb-10">
                <h2 class="text-xl font-semibold mb-4">About</h2>
                <p class="text-gray-600 text-lg leading-relaxed">
                    A fully convolutional autoencoder that removes Gaussian noise from face images. 
                    Trained on the <strong>LFWcrop dataset</strong> (64√ó64 color images), the network learns to 
                    reconstruct clean images from noisy inputs.
                </p>
                <a href="https://github.com/Asimawad/Fully-Convolutional-Networks-for-Image-Denoising" target="_blank" 
                   class="inline-flex items-center gap-2 mt-4 text-indigo-600 hover:text-indigo-700 font-medium">
                    View on GitHub ‚Üí
                </a>
            </section>

            <!-- Architecture -->
            <section class="mb-12">
                <h2 class="text-2xl font-bold mb-6 pb-2 border-b">Network Architecture</h2>
                
                <div class="grid md:grid-cols-2 gap-4 mb-6">
                    <div class="bg-white p-4 rounded-lg border">
                        <h3 class="font-semibold text-indigo-600 mb-2">Encoder</h3>
                        <ul class="text-sm text-gray-600 space-y-1">
                            <li>‚Ä¢ 4 convolutional layers with ReLU</li>
                            <li>‚Ä¢ 3 average pooling layers</li>
                            <li>‚Ä¢ Input: (3, 64, 64) ‚Üí Output: (32, 8, 8)</li>
                        </ul>
                    </div>
                    <div class="bg-white p-4 rounded-lg border">
                        <h3 class="font-semibold text-green-600 mb-2">Decoder</h3>
                        <ul class="text-sm text-gray-600 space-y-1">
                            <li>‚Ä¢ 4 transposed convolutional layers</li>
                            <li>‚Ä¢ Restores spatial dimensions</li>
                            <li>‚Ä¢ Input: (32, 8, 8) ‚Üí Output: (3, 64, 64)</li>
                        </ul>
                    </div>
                </div>

                <div class="bg-gray-50 p-4 rounded-lg border">
                    <h4 class="font-medium mb-2">Training Details:</h4>
                    <div class="grid grid-cols-2 md:grid-cols-4 gap-4 text-sm">
                        <div><span class="text-gray-500">Loss:</span> <span class="font-mono">MSE</span></div>
                        <div><span class="text-gray-500">Optimizer:</span> <span class="font-mono">Adam</span></div>
                        <div><span class="text-gray-500">LR:</span> <span class="font-mono">0.001</span></div>
                        <div><span class="text-gray-500">Epochs:</span> <span class="font-mono">50</span></div>
                    </div>
                </div>
            </section>

            <!-- Results -->
            <section class="mb-12">
                <h2 class="text-2xl font-bold mb-6 pb-2 border-b">Results</h2>

                <div class="grid grid-cols-2 gap-4 mb-6">
                    <div class="bg-white p-4 rounded-lg border text-center">
                        <p class="text-3xl font-bold text-green-600">0.0014</p>
                        <p class="text-sm text-gray-500">MSE (batch)</p>
                    </div>
                    <div class="bg-white p-4 rounded-lg border text-center">
                        <p class="text-3xl font-bold text-indigo-600">0.0015</p>
                        <p class="text-sm text-gray-500">MSE (full test set)</p>
                    </div>
                </div>

                <div class="mb-6">
                    <h3 class="text-lg font-semibold mb-3">Training & Validation Loss</h3>
                    <img src="https://raw.githubusercontent.com/Asimawad/Fully-Convolutional-Networks-for-Image-Denoising/main/plots/Train_val_loss_curves.png" 
                         alt="Training and Validation Loss" class="result-img w-full">
                    <p class="text-sm text-gray-500 mt-2">Smooth convergence over 50 epochs</p>
                </div>

                <div class="mb-6">
                    <h3 class="text-lg font-semibold mb-3">Qualitative Results: Noisy ‚Üí Denoised</h3>
                    <img src="https://raw.githubusercontent.com/Asimawad/Fully-Convolutional-Networks-for-Image-Denoising/main/plots/Qualitative_eval.png" 
                         alt="Qualitative Evaluation" class="result-img w-full">
                    <p class="text-sm text-gray-500 mt-2">Top row: noisy inputs | Bottom row: denoised reconstructions</p>
                </div>

                <div>
                    <h3 class="text-lg font-semibold mb-3">Example: Noisy vs Clean Training Data</h3>
                    <img src="https://raw.githubusercontent.com/Asimawad/Fully-Convolutional-Networks-for-Image-Denoising/main/plots/Example_Processed_images.png" 
                         alt="Example Processed Images" class="result-img w-full">
                </div>
            </section>

            <!-- Discussion -->
            <section class="mb-10">
                <h2 class="text-xl font-semibold mb-4">Discussion</h2>
                <div class="bg-white p-4 rounded-lg border">
                    <ul class="space-y-2 text-gray-600">
                        <li>‚Ä¢ Model effectively removes noise but sometimes produces slightly blurry reconstructions</li>
                        <li>‚Ä¢ Given the low quality of original LFWcrop images, results are impressive</li>
                        <li>‚Ä¢ Blurring occurs due to MSE loss smoothing pixel values</li>
                    </ul>
                </div>
            </section>

            <!-- Key Takeaways -->
            <section class="mb-10">
                <h2 class="text-xl font-semibold mb-4">Key Takeaways</h2>
                <div class="bg-gradient-to-r from-blue-50 to-cyan-50 p-6 rounded-xl">
                    <ul class="space-y-3 text-gray-700">
                        <li>‚úÖ <strong>Autoencoders work well</strong> for image denoising tasks</li>
                        <li>‚úÖ <strong>Fully convolutional</strong> architecture preserves spatial information</li>
                        <li>‚úÖ <strong>MSE loss</strong> achieves good quantitative results but can cause blurring</li>
                        <li>‚úÖ <strong>Future work:</strong> UNet architecture, perceptual loss, other noise types</li>
                    </ul>
                </div>
            </section>

            <!-- Footer Links -->
            <div class="flex justify-between items-center pt-6 border-t">
                <a href="/journey.html#chapter-2" class="text-gray-600 hover:text-gray-900">‚Üê Back to Journey</a>
                <a href="https://github.com/Asimawad/Fully-Convolutional-Networks-for-Image-Denoising" target="_blank" 
                   class="bg-gray-900 text-white px-4 py-2 rounded-lg hover:bg-gray-800 transition">
                    View on GitHub
                </a>
            </div>
        </div>
    </main>

    <footer class="py-8 bg-gray-900">
        <div class="max-w-4xl mx-auto px-6 text-center text-gray-500 text-sm">
            ¬© 2025 Asim Osman
        </div>
    </footer>
</body>
</html>
